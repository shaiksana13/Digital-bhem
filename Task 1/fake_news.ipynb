{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Required Libraries\n",
        "!pip install nltk textblob scikit-learn\n",
        "\n",
        "# Step 2: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Step 3: Define LIAR dataset column names\n",
        "columns = [\n",
        "    'id', 'label', 'statement', 'subject', 'speaker', 'job_title',\n",
        "    'state', 'party', 'barely_true', 'false', 'half_true', 'mostly_true',\n",
        "    'pants_on_fire', 'context'\n",
        "]\n",
        "\n",
        "# Step 4: Load .tsv files with correct headers\n",
        "train_df = pd.read_csv('/content/train.tsv', sep='\\t', header=None, names=columns)\n",
        "test_df = pd.read_csv('/content/test.tsv', sep='\\t', header=None, names=columns)\n",
        "valid_df = pd.read_csv('/content/valid.tsv', sep='\\t', header=None, names=columns)\n",
        "\n",
        "# Step 5: Combine all data\n",
        "df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
        "\n",
        "# Step 6: Convert labels to binary (FAKE = 0, REAL = 1)\n",
        "fake_labels = ['false', 'barely-true', 'pants-fire']\n",
        "real_labels = ['true', 'mostly-true', 'half-true']\n",
        "\n",
        "df['binary_label'] = df['label'].apply(lambda x: 0 if x in fake_labels else 1 if x in real_labels else None)\n",
        "df.dropna(subset=['binary_label'], inplace=True)\n",
        "\n",
        "# Step 7: Combine statement and context for full text\n",
        "df['content'] = df['statement'] + ' ' + df['context']\n",
        "\n",
        "# Step 8: Preprocess text manually without using nltk.tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()  # convert to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # remove non-alphabetic characters\n",
        "    words = text.split()  # split text into words\n",
        "    words = [stemmer.stem(word) for word in words if word not in stop_words]  # stem words and remove stopwords\n",
        "    return \" \".join(words)\n",
        "\n",
        "df['clean_text'] = df['content'].apply(preprocess_text)\n",
        "\n",
        "# Step 9: TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['clean_text']).toarray()\n",
        "y = df['binary_label'].values\n",
        "\n",
        "# Step 10: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 11: Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 12: Predict and Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Map 0 and 1 to 'fake' and 'real'\n",
        "label_mapping = {0: 'fake', 1: 'real'}\n",
        "\n",
        "# Convert predictions to 'real' and 'fake' strings\n",
        "y_pred_labels = [label_mapping[label] for label in y_pred]\n",
        "y_test_labels = [label_mapping[label] for label in y_test]\n",
        "\n",
        "# Print the classification report\n",
        "print(\"ðŸ“Š Classification Report:\\n\")\n",
        "print(classification_report(y_test_labels, y_pred_labels))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"ðŸ§© Confusion Matrix:\\n\")\n",
        "print(confusion_matrix(y_test_labels, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB47_b3NaVJO",
        "outputId": "670f3e8c-ddf8-4790-a611-5801780be35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "ðŸ“Š Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.60      0.49      0.54      1121\n",
            "        real       0.65      0.75      0.70      1438\n",
            "\n",
            "    accuracy                           0.63      2559\n",
            "   macro avg       0.63      0.62      0.62      2559\n",
            "weighted avg       0.63      0.63      0.63      2559\n",
            "\n",
            "ðŸ§© Confusion Matrix:\n",
            "\n",
            "[[ 544  577]\n",
            " [ 362 1076]]\n"
          ]
        }
      ]
    }
  ]
}